{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-requisites\n"
      ],
      "metadata": {
        "id": "7o-fotEbZtig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing required packages\n"
      ],
      "metadata": {
        "id": "qw3Kp7SIZvr1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ps91OMfSRq_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f179e684-5248-44a2-bdc7-dce910ddd95b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-ueai3_w8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-ueai3_w8\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment_anything\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36592 sha256=359591c2d9f8715ae10bc3402de15754cf07934fed240b8228c45bbe3c7fca89\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0kb4_kpo/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment_anything\n",
            "Installing collected packages: segment_anything\n",
            "Successfully installed segment_anything-1.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mediapipe\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.48-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.48-py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.8/898.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.48 ultralytics-thop-2.0.13\n",
            "Collecting zip\n",
            "  Downloading zip-0.0.2.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-Admin>=1.0.4 (from zip)\n",
            "  Downloading Flask_Admin-1.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting Flask-Bootstrap>=2.2.2-1 (from zip)\n",
            "  Downloading Flask-Bootstrap-3.3.7.1.tar.gz (456 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-Cache>=0.10.1 (from zip)\n",
            "  Downloading Flask-Cache-0.13.1.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-FlatPages>=0.3 (from zip)\n",
            "  Downloading Flask_FlatPages-0.8.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting Flask-Gravatar>=0.2.4 (from zip)\n",
            "  Downloading Flask_Gravatar-0.5.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting Flask-Login>=0.1.3 (from zip)\n",
            "  Downloading Flask_Login-0.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting Flask-Mail>=0.7.4 (from zip)\n",
            "  Downloading flask_mail-0.10.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting Flask-PyMongo>=0.2.1 (from zip)\n",
            "  Downloading Flask_PyMongo-2.3.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting Flask-Restless>=0.9.1 (from zip)\n",
            "  Downloading Flask-Restless-0.17.0.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-SQLAlchemy>=0.16 (from zip)\n",
            "  Downloading flask_sqlalchemy-3.1.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting Flask-Themes>=0.1.3 (from zip)\n",
            "  Downloading Flask-Themes-0.1.3.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-Uploads>=0.1.3 (from zip)\n",
            "  Downloading Flask-Uploads-0.2.1.tar.gz (7.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-WTF>=0.8.2 (from zip)\n",
            "  Downloading flask_wtf-1.2.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from zip) (3.0.3)\n",
            "Collecting frozen-flask (from zip)\n",
            "  Downloading frozen_flask-1.0.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: Jinja2>=2.6 in /usr/local/lib/python3.10/dist-packages (from zip) (3.1.4)\n",
            "Requirement already satisfied: Markdown>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from zip) (3.7)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from zip) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=0.8.0b2 in /usr/local/lib/python3.10/dist-packages (from zip) (2.0.36)\n",
            "Requirement already satisfied: Sphinx>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from zip) (8.1.3)\n",
            "Collecting WTForms>=1.0.3 (from zip)\n",
            "  Downloading wtforms-3.2.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Werkzeug>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from zip) (3.1.3)\n",
            "Collecting argparse>=1.2.1 (from zip)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: blinker>=1.2 in /usr/local/lib/python3.10/dist-packages (from zip) (1.9.0)\n",
            "Collecting bumpversion>=0.5.3 (from zip)\n",
            "  Downloading bumpversion-0.6.0-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click>=6.3 in /usr/local/lib/python3.10/dist-packages (from zip) (8.1.7)\n",
            "Collecting colorama>=0.3.7 (from zip)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting coverage>=4.0 (from zip)\n",
            "  Downloading coverage-7.6.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: cryptography>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from zip) (43.0.3)\n",
            "Collecting flake8>=2.4.1 (from zip)\n",
            "  Downloading flake8-7.1.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from zip) (3.4.2)\n",
            "Collecting pymongo>=2.5.1 (from zip)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pytest>=2.8.3 in /usr/local/lib/python3.10/dist-packages (from zip) (8.3.4)\n",
            "Requirement already satisfied: python-dateutil>=1.5 in /usr/local/lib/python3.10/dist-packages (from zip) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from zip) (1.16.0)\n",
            "Collecting tox>=2.1.1 (from zip)\n",
            "  Downloading tox-4.23.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting watchdog>=0.8.3 (from zip)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from zip) (0.45.1)\n",
            "Collecting wsgiref>=0.1.2 (from zip)\n",
            "  Downloading wsgiref-0.1.2.zip (37 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "%pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "%pip install -q roboflow supervision\n",
        "!wget -q 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
        "%pip install mediapipe\n",
        "%pip install ultralytics\n",
        "%pip install zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing all the required libraries\n"
      ],
      "metadata": {
        "id": "RHpkFQ6RaK3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
        "from google.colab.patches import cv2_imshow\n",
        "import mediapipe as mp\n",
        "import csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOGrhgrHaJbS",
        "outputId": "3c617a58-4cb1-4fc0-cbd6-c595de5366ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating frames to use\n"
      ],
      "metadata": {
        "id": "5pKcAs_uh6kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating image frames from video input"
      ],
      "metadata": {
        "id": "jUBP4rrFbVHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def video_to_frames(input_video_path, output_folder, fps=20):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Get the original frames per second (fps) of the video\n",
        "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Get the total number of frames in the video\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(original_fps)\n",
        "    print(total_frames)\n",
        "    # Calculate the interval between frames based on the desired fps\n",
        "    interval = int(original_fps / fps)\n",
        "    print(interval)\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    frame_number = 0\n",
        "    saved_frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break  # Break if the video ends\n",
        "\n",
        "        # Save frames at the specified interval\n",
        "        if frame_number % interval == 0:\n",
        "            frame_filename = os.path.join(output_folder, f\"frame_{saved_frame_count:04d}.jpg\")\n",
        "            cv2.imwrite(frame_filename, frame)  # Save frame as image\n",
        "            saved_frame_count += 1\n",
        "\n",
        "        frame_number += 1\n",
        "\n",
        "    cap.release()  # Release the video capture object\n",
        "    print(f\"Extracted {saved_frame_count} frames.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "B351KEYnbg-m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_video_path = 'input_video.mp4'\n",
        "output_folder = 'Image_frames'\n",
        "fps = 15\n",
        "\n",
        "video_to_frames(input_video_path, output_folder, fps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfBAS4mxLiSD",
        "outputId": "43b7f574-7958-4190-ea2e-d43d135cbc0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.0\n",
            "1187\n",
            "2\n",
            "Extracted 594 frames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task - 1"
      ],
      "metadata": {
        "id": "Bz5i0540VF_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading YOLOv8 and SAM model"
      ],
      "metadata": {
        "id": "isaHYj7BaWLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load YOLOv8 model (for human detection)\n",
        "model = YOLO(\"yolov8l.pt\")\n",
        "\n",
        "# Load SAM model\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\"\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint='sam_vit_h_4b8939.pth')\n",
        "sam.to(device=DEVICE)\n",
        "mask_predictor = SamPredictor(sam)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdoWG39maWif",
        "outputId": "d9685dd2-7db3-48a5-f984-5de38eef65a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83.7M/83.7M [00:00<00:00, 342MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the input and output directories"
      ],
      "metadata": {
        "id": "nErXXoW5aeoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and output directories\n",
        "input_dir = 'Image_frames'  # Directory containing input images\n",
        "output_dir = 'Segmented_frames'  # Directory to save segmented images\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "xXcoBHHVaeXB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funtion to execute YOLO and SAM Segementation"
      ],
      "metadata": {
        "id": "-nFG8xIuavWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Process each image in the input directory\n",
        "for image_file in os.listdir(input_dir):\n",
        "    if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image_path = os.path.join(input_dir, image_file)\n",
        "        print(image_path)\n",
        "        img = Image.open(image_path)\n",
        "\n",
        "        # Convert to OpenCV format\n",
        "        img_cv = np.array(img)\n",
        "        img_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Apply YOLOv8 to detect persons in the image\n",
        "        results = model(img_cv)  # Run YOLOv8 on the image\n",
        "\n",
        "        # Extract detection results\n",
        "        boxes = results[0].boxes  # Get bounding boxes from the first result\n",
        "        confidences = boxes.conf  # Confidence scores of detections\n",
        "\n",
        "        # List to store bounding box coordinates for detected persons\n",
        "        person_boxes = []\n",
        "        for box, conf in zip(boxes.xywh, confidences):\n",
        "            if conf > 0:\n",
        "                x, y, w, h = box  # Extract box coordinates (x, y, width, height)\n",
        "                x1, y1, x2, y2 = int(x - w / 2), int(y - h / 2), int(x + w / 2), int(y + h / 2)\n",
        "                person_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "        all_masks = []\n",
        "\n",
        "        # Process each detected person box\n",
        "\n",
        "        if person_boxes:\n",
        "          box = person_boxes[0]\n",
        "          box_np = np.array([\n",
        "              box[0],  # x1\n",
        "              box[1],  # y1\n",
        "              box[2],  # x2\n",
        "              box[3]   # y2\n",
        "          ])\n",
        "\n",
        "          # Set the image for the mask predictor\n",
        "          mask_predictor.set_image(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "          # Perform segmentation using the bounding box\n",
        "          masks, scores, logits = mask_predictor.predict(\n",
        "              box=box_np,\n",
        "              multimask_output=True\n",
        "          )\n",
        "\n",
        "          # Append the masks to the all_masks list\n",
        "          all_masks.extend(masks)\n",
        "\n",
        "        # Combine all masks into a single mask\n",
        "        if all_masks:\n",
        "            combined_mask = np.sum(all_masks, axis=0) > 0\n",
        "        else:\n",
        "            combined_mask = np.zeros_like(img_cv[:, :, 0], dtype=bool)\n",
        "\n",
        "        # Create a transparent overlay\n",
        "        overlay = img_cv.copy()\n",
        "        overlay[combined_mask] = [0, 255, 0]\n",
        "\n",
        "        # Create an alpha channel for transparency\n",
        "        alpha = 0.5\n",
        "        transparent_mask = cv2.addWeighted(overlay, alpha, img_cv, 1 - alpha, 0)\n",
        "\n",
        "        # Save the transparent mask image\n",
        "        output_path = os.path.join(output_dir, f'{image_file}')\n",
        "        cv2.imwrite(output_path, transparent_mask)  # Save the image"
      ],
      "metadata": {
        "id": "7roTTK26a4XM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41631a95-3dd0-4dce-d30c-dd72cfb05753"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image_frames/frame_0060.jpg\n",
            "\n",
            "0: 384x640 1 person, 117.9ms\n",
            "Speed: 14.1ms preprocess, 117.9ms inference, 771.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Image_frames/test_image.jpg\n",
            "\n",
            "0: 320x640 1 person, 63.6ms\n",
            "Speed: 3.2ms preprocess, 63.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the segemented frames into zip file for future use"
      ],
      "metadata": {
        "id": "m4HmuZeybxLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r Segmented_frames.zip Segmented_frames/"
      ],
      "metadata": {
        "id": "CoXRxFGVbwkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdaa58e1-7ae0-4b22-f98f-d21cd12796e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: Segmented_frames/ (stored 0%)\n",
            "  adding: Segmented_frames/frame_0060.jpg (deflated 0%)\n",
            "  adding: Segmented_frames/test_image.jpg (deflated 2%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to create segmented video from the segmented frames"
      ],
      "metadata": {
        "id": "NStdmTF_b6FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_to_video(output_folder, output_video_path, fps=20):\n",
        "    # Get all the frame filenames in sorted order\n",
        "    frame_files = sorted([f for f in os.listdir(output_folder) if f.endswith('.jpg')])\n",
        "\n",
        "    # Read the first frame to get dimensions\n",
        "    first_frame = cv2.imread(os.path.join(output_folder, frame_files[0]))\n",
        "    height, width, _ = first_frame.shape\n",
        "\n",
        "    # Initialize video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can use other codecs too\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Write frames to video\n",
        "    for frame_file in frame_files:\n",
        "        frame_path = os.path.join(output_folder, frame_file)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    print(f\"Video saved to {output_video_path}\")\n",
        "\n",
        "\n",
        "output_video_path = 'segmented_video.mp4'\n",
        "frames_to_video(output_dir, output_video_path, fps=15)\n"
      ],
      "metadata": {
        "id": "-YpF6AaVb-ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c82669-8d42-4ae7-dfc9-882bdbc7c838"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video saved to segmented_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task - 2"
      ],
      "metadata": {
        "id": "lyeuC8GVrEXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Yolo\n"
      ],
      "metadata": {
        "id": "1SsoV3ezVRYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Load YOLOv8 model (for human detection)\n",
        "model = YOLO(\"yolov8l.pt\")\n",
        "\n",
        "# 2. Load Pose Estimation Model (using MediaPipe)\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "# 3. Define the folder containing the images\n",
        "pose_folder = 'Poses'  # Folder to save pose estimated images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1g214uKeFu0",
        "outputId": "68f08148-bb3e-4e7f-c219-a4c86b56e43d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 97.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating csv file for key point use"
      ],
      "metadata": {
        "id": "TL167bCEVmdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make sure the \"poses\" folder exists\n",
        "os.makedirs(pose_folder, exist_ok=True)\n",
        "\n",
        "# Define the CSV file to store keypoints\n",
        "csv_file = 'pose_keypoints.csv'\n",
        "\n",
        "# Create or overwrite CSV file and write headers\n",
        "with open(csv_file, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Image Name', 'Keypoint Index', 'X', 'Y', 'Visibility'])\n"
      ],
      "metadata": {
        "id": "4IqOfyZGelub"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pose estimation and using YOLO and mediaPipe, also saving the keypoints coordinates in the csv file"
      ],
      "metadata": {
        "id": "tBCB4m5LV_Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Loop over all images in the folder\n",
        "for image_name in os.listdir(input_dir):\n",
        "    if image_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        # Load the image\n",
        "        img_path = os.path.join(input_dir, image_name)\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        # Convert to OpenCV format\n",
        "        img_cv = np.array(img)\n",
        "        img_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # 5. Preprocessing: Apply Gaussian blur or median filter to reduce noise from water bubbles\n",
        "        img_blur = cv2.GaussianBlur(img_cv, (5, 5), 0)\n",
        "\n",
        "        # 6. Apply YOLOv8 to detect swimmers (humans) in the image\n",
        "        results = model(img_blur)\n",
        "\n",
        "        # Extract detection results\n",
        "        boxes = results[0].boxes  # Get bounding boxes from the first result\n",
        "        labels = results[0].names  # Get class names from the model\n",
        "        confidences = boxes.conf  # Confidence scores of detections\n",
        "\n",
        "        # 7. Draw bounding boxes on the image if confidence > threshold\n",
        "        for box, conf in zip(boxes.xywh, confidences):\n",
        "            if conf > 0:\n",
        "                x, y, w, h = box  # Extract box coordinates (x, y, width, height)\n",
        "                x1, y1, x2, y2 = int(x - w / 2), int(y - h / 2), int(x + w / 2), int(y + h / 2)\n",
        "\n",
        "                # Draw a rectangle around the detected object\n",
        "                cv2.rectangle(img_cv, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "                # Annotate with the class label and confidence score\n",
        "                label = f'{labels[int(boxes.cls[0])]}: {conf:.2f}'\n",
        "                cv2.putText(img_cv, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # 8. Pose estimation using MediaPipe to detect keypoints of the swimmer\n",
        "        image_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Perform pose estimation\n",
        "        results_pose = pose.process(image_rgb)\n",
        "\n",
        "        # 9. Extract and store keypoint coordinates, and draw keypoints on the image\n",
        "        if results_pose.pose_landmarks:\n",
        "            for idx, landmark in enumerate(results_pose.pose_landmarks.landmark):\n",
        "                x = landmark.x  # X coordinate (normalized to [0, 1])\n",
        "                y = landmark.y  # Y coordinate (normalized to [0, 1])\n",
        "                visibility = landmark.visibility  # Visibility score\n",
        "\n",
        "                # Convert normalized coordinates to pixel values\n",
        "                h, w, _ = img_cv.shape\n",
        "                x_pixel = int(x * w)\n",
        "                y_pixel = int(y * h)\n",
        "\n",
        "                # Draw keypoints on the image (in red)\n",
        "                if visibility > 0:\n",
        "                    cv2.circle(img_cv, (x_pixel, y_pixel), 5, (0, 0, 255), -1)\n",
        "\n",
        "                # Write the keypoints to the CSV file\n",
        "                with open(csv_file, 'a', newline='') as f:\n",
        "                    writer = csv.writer(f)\n",
        "                    writer.writerow([image_name, idx, x, y, visibility])\n",
        "\n",
        "        # 10. Draw Pose Connections on the image (connecting keypoints)\n",
        "        if results_pose.pose_landmarks:\n",
        "            mp.solutions.drawing_utils.draw_landmarks(img_cv, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "        # 11. Save the final image with both bounding boxes (from YOLOv8) and pose keypoints to the \"poses\" folder\n",
        "        pose_image_path = os.path.join(pose_folder, image_name)\n",
        "        cv2.imwrite(pose_image_path, img_cv)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgyhKbrWRzjU",
        "outputId": "8fb59d3d-3211-4d29-9c51-1df612f40e4a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 89.9ms\n",
            "Speed: 1.5ms preprocess, 89.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 320x640 1 person, 32.4ms\n",
            "Speed: 3.5ms preprocess, 32.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the estimated frames in a zip file for future use\n"
      ],
      "metadata": {
        "id": "oqcFPu93WBZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r Poses_frames.zip Poses/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qVYlDtvf1zI",
        "outputId": "3a3aa566-8824-4eba-9d43-b6fa3ac6aab8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: Poses/ (stored 0%)\n",
            "  adding: Poses/frame_0060.jpg (deflated 0%)\n",
            "  adding: Poses/test_image.jpg (deflated 2%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the estimated frames to video"
      ],
      "metadata": {
        "id": "IXkoO3jLWF1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_to_video(output_folder, output_video_path, fps=20):\n",
        "    # Get all the frame filenames in sorted order\n",
        "    frame_files = sorted([f for f in os.listdir(output_folder) if f.endswith('.jpg')])\n",
        "\n",
        "    # Read the first frame to get dimensions\n",
        "    first_frame = cv2.imread(os.path.join(output_folder, frame_files[0]))\n",
        "    height, width, _ = first_frame.shape\n",
        "\n",
        "    # Initialize video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can use other codecs too\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Write frames to video\n",
        "    for frame_file in frame_files:\n",
        "        frame_path = os.path.join(output_folder, frame_file)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    print(f\"Video saved to {output_video_path}\")\n",
        "\n",
        "\n",
        "output_video_path = 'pose_video.mp4'\n",
        "frames_to_video(pose_folder, output_video_path, fps=15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HcQ_Sybexbh",
        "outputId": "b3cb5130-29d3-4ddc-81cf-994960b45290"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video saved to pose_video.mp4\n"
          ]
        }
      ]
    }
  ]
}
